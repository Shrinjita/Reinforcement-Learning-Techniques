{"cells":[{"cell_type":"markdown","metadata":{"id":"1c6X7cAOl8wG"},"source":["https://github.com/MohammadAsadolahi/Reinforcement-Learning-solving-a-simple-4by4-Gridworld-using-policy-iteration-in-python/blob/main/README.md"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"_gVBm7gDHgUt","executionInfo":{"status":"ok","timestamp":1740712136221,"user_tz":-330,"elapsed":42,"user":{"displayName":"SHRINJITA PAUL (RA2211047010017)","userId":"01697648162985420992"}}},"outputs":[],"source":["import numpy as np\n","\n","class GridWorld:\n","    def __init__(self):\n","        # S O O O\n","        # O O O *\n","        # O * O O\n","        # O * 0 T\n","        self.actionSpace = ('U', 'D', 'L', 'R')\n","        self.actions = {\n","            (0, 0): ('D', 'R'),\n","            (0, 1): ('L', 'D', 'R'),\n","            (0, 2): ('L', 'D', 'R'),\n","            (0, 3): ('L', 'D'),\n","            (1, 0): ('U', 'D', 'R'),\n","            (1, 1): ('U', 'L', 'D', 'R'),\n","            (1, 2): ('U', 'L', 'D', 'R'),\n","            (1, 3): ('U', 'L', 'D'),\n","            (2, 0): ('U', 'D', 'R'),\n","            (2, 1): ('U', 'L', 'D', 'R'),\n","            (2, 2): ('U', 'L', 'D', 'R'),\n","            (2, 3): ('U', 'L', 'D'),\n","            (3, 0): ('U', 'R'),\n","            (3, 1): ('U', 'L', 'R'),\n","            (3, 2): ('U', 'L', 'R')\n","        }\n","        self.rewards = {(3, 3): 0.03, (1, 3): -0.01, (2, 1): -0.011, (3, 1): -0.01}\n","        self.explored = 0\n","        self.exploited = 0\n","\n","    def getRandomPolicy(self):\n","        policy = {}\n","        for state in self.actions:\n","            policy[state] = np.random.choice(self.actions[state])\n","        return policy\n","\n","    def reset(self):\n","        return (0, 0)\n","\n","    def is_terminal(self, s):\n","        return s not in self.actions\n","\n","    def getNewState(self, state, action):\n","        i, j = zip(state)\n","        row = int(i[0])\n","        column = int(j[0])\n","        if action == 'U':\n","            row -= 1\n","        elif action == 'D':\n","            row += 1\n","        elif action == 'L':\n","            column -= 1\n","        elif action == 'R':\n","            column += 1\n","        return row, column\n","\n","    def chooseAction(self, state, policy, exploreRate):\n","        # Step 1: Generate a random number between 0 and 1\n","        random_value = np.random.rand()\n","\n","        # Step 2 & 3: Compare with exploreRate\n","        if random_value < exploreRate:\n","            self.explored += 1\n","            return np.random.choice(self.actions[state])\n","        else:\n","            self.exploited += 1\n","            return policy[state]\n","\n","    def greedyChoose(self, state, values):\n","        possibleActions = self.actions[state]\n","        stateValues = []\n","\n","        for action in possibleActions:\n","            nextState = self.getNewState(state, action)\n","            stateValues.append(values.get(nextState, 0))\n","\n","        bestActionIndex = np.argmax(stateValues)\n","        return possibleActions[bestActionIndex]\n","\n","    def move(self, state, policy, exploreRate):\n","        action = self.chooseAction(state, policy, exploreRate)\n","        newState = self.getNewState(state, action)\n","        reward = self.rewards.get(newState, 0)\n","        return newState, reward\n","\n","    def printValues(self, values):\n","        line = \"\"\n","        counter = 0\n","        for item in values:\n","            line += f\" | {values[item]} | \"\n","            counter += 1\n","            if counter > 3:\n","                print(line)\n","                print(\"--------------------------------\")\n","                counter = 0\n","                line = \"\"\n","        print(line)\n","        print(\"----------------------------\")\n","\n","    def printPolicy(self, policy):\n","        line = \"\"\n","        counter = 0\n","        for item in policy:\n","            line += f\" | {policy[item]} | \"\n","            counter += 1\n","            if counter > 3:\n","                print(line)\n","                print(\"----------------------------\")\n","                counter = 0\n","                line = \"\"\n","        print(line)\n","        print(\"----------------------------\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"yma4qfqfHkga","executionInfo":{"status":"ok","timestamp":1740712194168,"user_tz":-330,"elapsed":55346,"user":{"displayName":"SHRINJITA PAUL (RA2211047010017)","userId":"01697648162985420992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"30c2b6cd-7b6a-4a54-936b-0912ee3235fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n"," step:0\n"," | R |  | D |  | L |  | L | \n","----------------------------\n"," | R |  | U |  | U |  | U | \n","----------------------------\n"," | R |  | U |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | R | \n","----------------------------\n","\n","\n","\n"," step:100\n"," | R |  | D |  | L |  | L | \n","----------------------------\n"," | R |  | U |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | R | \n","----------------------------\n","\n","\n","\n"," step:200\n"," | R |  | D |  | D |  | D | \n","----------------------------\n"," | R |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | R | \n","----------------------------\n","\n","\n","\n"," step:300\n"," | R |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | D |  | D | \n","----------------------------\n"," | R |  | D |  | D |  | D | \n","----------------------------\n"," | R |  | R |  | R | \n","----------------------------\n","\n","\n","\n"," step:400\n"," | D |  | D |  | D |  | D | \n","----------------------------\n"," | R |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | R | \n","----------------------------\n","\n","\n","\n"," step:500\n"," | R |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | R | \n","----------------------------\n","\n","\n","\n"," step:600\n"," | D |  | D |  | D |  | D | \n","----------------------------\n"," | R |  | D |  | D |  | D | \n","----------------------------\n"," | R |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | R | \n","----------------------------\n","\n","\n","\n"," step:700\n"," | R |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | D |  | D |  | D | \n","----------------------------\n"," | R |  | R |  | R | \n","----------------------------\n","\n","\n","\n"," step:800\n"," | R |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | D |  | D |  | D | \n","----------------------------\n"," | R |  | R |  | D |  | D | \n","----------------------------\n"," | R |  | R |  | R | \n","----------------------------\n","\n","\n","\n"," step:900\n"," | R |  | R |  | L |  | D | \n","----------------------------\n"," | U |  | D |  | D |  | D | \n","----------------------------\n"," | R |  | D |  | D |  | D | \n","----------------------------\n"," | R |  | R |  | R | \n","----------------------------\n","\n","\n","\n"," step:1000\n"," | R |  | R |  | D |  | D | \n","----------------------------\n"," | U |  | R |  | D |  | D | \n","----------------------------\n"," | D |  | D |  | D |  | D | \n","----------------------------\n"," | R |  | R |  | R | \n","----------------------------\n","exploited:11979762  explored:630024\n"]}],"source":["enviroment = GridWorld()\n","policy = enviroment.getRandomPolicy()\n","# enviroment.printPolicy(policy)\n","\n","#example optimal policy = {(0, 0): 'R', (0, 1): 'R', (0, 2): 'D', (0, 3): 'D', (1, 0): 'R', (1, 1): 'D', (1, 2): 'D', (1, 3): 'D',\n","#           (2, 0): 'R', (2, 1): 'D', (2, 2): 'R', (2, 3): 'D', (3, 0): 'R', (3, 1): 'R', (3, 2): 'R'}\n","\n","for i in range(1001):\n","  values = {}\n","  for state in policy:\n","      values[state] = 0\n","  values[(3, 3)] = 5\n","\n","  for j in range(1000):\n","    state = enviroment.reset()\n","    stepCounts=0\n","    while (not enviroment.is_terminal(state)) and (stepCounts<50):\n","      nextState, reward = enviroment.move(state, policy, exploreRate=0.05)\n","      values[state] = reward + 0.1 * values[nextState]\n","      state=nextState\n","      stepCounts+=1\n","  for item in policy:\n","        policy[item] = enviroment.greedyChoose(item, values)\n","\n","  if (i%100)==0:\n","    print(f\"\\n\\n\\n step:{i}\")\n","    # enviroment.printVaues(values)\n","    enviroment.printPolicy(policy)\n","\n","print(f\"exploited:{enviroment.exploited}  explored:{enviroment.explored}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}