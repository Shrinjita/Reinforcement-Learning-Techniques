{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPiwAFoe1tVSH7mXvbKsUfF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxGzO3uzY8_Y","executionInfo":{"status":"ok","timestamp":1739502105462,"user_tz":-330,"elapsed":377,"user":{"displayName":"SHRINJITA PAUL (RA2211047010017)","userId":"01697648162985420992"}},"outputId":"f302993a-7980-44ba-d614-67719178257a"},"outputs":[{"output_type":"stream","name":"stdout","text":["iteration: 1\n","Epsilon criteria satisfied!\n","Q matrix (optimal):\n","[[0.    0.   ]\n"," [1.    0.   ]\n"," [0.5   0.   ]\n"," [0.25  0.   ]\n"," [0.125 5.   ]\n"," [0.    0.   ]]\n","Q(optimal):\n","[0 0 0 0 1 0]\n","Optimal Policy:\n","*\n","[-1, -1, -1, 1]\n","*\n"]}],"source":["import numpy as np\n","\n","def deterministic_robot_cleaning_v1():\n","    # Initialization\n","    state = [1, 2, 3, 4, 5, 6]                # Set of states\n","    action = [-1, 1]                         # Set of actions\n","    Q = np.zeros((len(state), len(action)))  # Initial Q can be chosen arbitrarily\n","    Qold = Q                                 # Save a backup to compare later\n","    L = 15                                   # Number of iterations\n","    gamma = 0.5                              # Discounting factor\n","    epsilon = 0.001                          # Final error to stop the algorithm\n","\n","    # Deterministic Q-iteration algorithm\n","    for l in range(1, L + 1):\n","        print(f'iteration: {l}')\n","        for ii in range(len(state)):\n","            for jj in range(len(action)):\n","                Q[ii, jj] = reward(state[ii], action[jj]) + gamma * Q[model(state[ii], action[jj], state), jj]\n","        if np.abs(np.sum(Q - Qold)) < epsilon:\n","            print('Epsilon criteria satisfied!')\n","            break\n","        else:\n","            # print(Q)                            # Show Q matrix in each iteration\n","            Qold = Q\n","\n","    # Show the final Q matrix\n","    print('Q matrix (optimal):')\n","    print(Q)\n","\n","    C = np.argmax(Q, axis=1)                   # Finding the max values\n","    print('Q(optimal):')\n","    print(C)\n","    print('Optimal Policy:')\n","    print('*')\n","    print([action[C[1]], action[C[2]], action[C[3]], action[C[4]]])\n","    print('*')\n","\n","\n","# This function is the transition model of the robot\n","# The inputs are: the current state, and the chosen action\n","# The output is the next state\n","def model(x, u, state):\n","    if 2 <= x <= 5:\n","        return state.index(x + u)  # Convert state value to index\n","    else:\n","        return state.index(x)      # Convert state value to index\n","\n","# This function is the reward function for the task\n","# The inputs are: the current state, and the chosen action\n","# The output is the expected reward\n","def reward(x, u):\n","    if x == 5 and u == 1:\n","        return 5\n","    elif x == 2 and u == -1:\n","        return 1\n","    else:\n","        return 0\n","\n","# Call the main function\n","deterministic_robot_cleaning_v1()"]},{"cell_type":"code","source":[],"metadata":{"id":"szTkKlgwZEMX"},"execution_count":null,"outputs":[]}]}