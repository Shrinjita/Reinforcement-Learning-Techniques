{"cells":[{"cell_type":"code","source":["import numpy as np\n","import pickle\n","\n","# Define board dimensions\n","board_rows = 3\n","board_cols = 3\n","\n","class State:\n","    def __init__(self, p1, p2):\n","        # Initialize the board state with zeros\n","        self.board = np.zeros((board_rows, board_cols))\n","        self.p1 = p1  # Player 1\n","        self.p2 = p2  # Player 2\n","        self.isEnd = False  # Flag to check if the game has ended\n","        self.boardHash = None  # Stores the board state hash\n","        self.playerSymbol = 1  # Player 1 starts first\n","\n","    def getHash(self):\n","        # Converts board state to a hashable string\n","        self.boardHash = str(self.board.reshape(board_rows * board_cols))\n","        return self.boardHash\n","\n","    def availablePositions(self):\n","        # Returns a list of empty positions on the board\n","        return [(i, j) for i in range(board_rows) for j in range(board_cols) if self.board[i, j] == 0]\n","\n","    def updateState(self, position):\n","        # Updates the board with the current player's move\n","        self.board[position] = self.playerSymbol\n","        # Switch player after making a move\n","        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n","\n","    def winner(self):\n","        # Check for winning conditions\n","        for i in range(board_rows):\n","            if sum(self.board[i, :]) == 3:  # Player 1 wins\n","                return 1\n","            if sum(self.board[i, :]) == -3:  # Player 2 wins\n","                return -1\n","\n","        for i in range(board_cols):\n","            if sum(self.board[:, i]) == 3:  # Column-wise win for Player 1\n","                return 1\n","            if sum(self.board[:, i]) == -3:  # Column-wise win for Player 2\n","                return -1\n","\n","        # Check diagonals\n","        diag1 = sum([self.board[i, i] for i in range(board_rows)])\n","        diag2 = sum([self.board[i, board_rows - i - 1] for i in range(board_rows)])\n","\n","        if diag1 == 3 or diag2 == 3:\n","            return 1\n","        if diag1 == -3 or diag2 == -3:\n","            return -1\n","\n","        # Check for a draw (no available positions left)\n","        if len(self.availablePositions()) == 0:\n","            return 0\n","\n","        return None  # Game is still ongoing\n","\n","    def giveReward(self):\n","        # Assigns rewards to players based on game outcome\n","        result = self.winner()\n","        if result == 1:\n","            self.p1.feedReward(1)\n","            self.p2.feedReward(0)\n","        elif result == -1:\n","            self.p1.feedReward(0)\n","            self.p2.feedReward(1)\n","        else:\n","            self.p1.feedReward(0.1)  # Reward for a draw\n","            self.p2.feedReward(0.5)\n","\n","    def reset(self):\n","        # Resets the board for a new game\n","        self.board = np.zeros((board_rows, board_cols))\n","        self.boardHash = None\n","        self.isEnd = False\n","        self.playerSymbol = 1\n","\n","    def play(self, rounds=100):\n","        # Simulates training for a given number of rounds\n","        for i in range(rounds):\n","            if i % 1000 == 0:\n","                print(\"Rounds {}\".format(i))\n","            while self.winner() is None:\n","                positions = self.availablePositions()\n","                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n","                self.updateState(p1_action)\n","                self.p1.addState(self.getHash())\n","\n","                if self.winner() is not None:\n","                    self.giveReward()\n","                    self.p1.reset()\n","                    self.p2.reset()\n","                    self.reset()\n","                    break\n","\n","                positions = self.availablePositions()\n","                p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n","                self.updateState(p2_action)\n","                self.p2.addState(self.getHash())\n","\n","                if self.winner() is not None:\n","                    self.giveReward()\n","                    self.p1.reset()\n","                    self.p2.reset()\n","                    self.reset()\n","                    break\n","\n","    def showBoard(self):\n","        # Prints the current board state\n","        for i in range(board_rows):\n","            print('-------------')\n","            out = '| '\n","            for j in range(board_cols):\n","                token = 'x' if self.board[i, j] == 1 else 'o' if self.board[i, j] == -1 else ' '\n","                out += token + ' | '\n","            print(out)\n","        print('-------------')\n","\n","class Player:\n","    def __init__(self, name, exp_rate=0.3):\n","        self.name = name\n","        self.states = []  # Stores states encountered\n","        self.lr = 0.2  # Learning rate\n","        self.exp_rate = exp_rate  # Exploration rate\n","        self.decay_gamma = 0.9  # Discount factor\n","        self.states_value = {}  # Stores value function\n","\n","    def getHash(self, board):\n","        return str(board.reshape(board_cols * board_rows))\n","\n","    def addState(self, state):\n","        self.states.append(state)\n","\n","    def feedReward(self, reward):\n","        # Backpropagates rewards through previous states\n","        for st in reversed(self.states):\n","            if self.states_value.get(st) is None:\n","                self.states_value[st] = 0\n","            self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n","            reward = self.states_value[st]\n","\n","    def reset(self):\n","        self.states = []\n","\n","    def savePolicy(self):\n","        with open('policy_' + str(self.name), 'wb') as fw:\n","            pickle.dump(self.states_value, fw)\n","\n","    def loadPolicy(self, file):\n","        with open(file, 'rb') as fr:\n","            self.states_value = pickle.load(fr)\n","\n","    def chooseAction(self, positions, board, symbol):\n","        return positions[0]  # Currently chooses first available position\n","\n","class HumanPlayer:\n","    def __init__(self, name):\n","        self.name = name\n","\n","    def chooseAction(self, positions, board=None, symbol=None):\n","        while True:\n","            row = int(input(\"Input your action row:\"))\n","            col = int(input(\"Input your action col:\"))\n","            action = (row, col)\n","            if action in positions:\n","                return action\n","\n","# Training phase\n","p1 = Player(\"p1\")\n","p2 = Player(\"p2\")\n","st = State(p1, p2)\n","print(\"training...\")\n","st.play(50000)\n","p1.savePolicy()\n","p2.savePolicy()\n","\n","# Load trained policy and start human vs AI game\n","p1 = Player(\"computer\", exp_rate=0)\n","p1.loadPolicy(\"policy_p1\")\n","p2 = HumanPlayer(\"human\")\n","st = State(p1, p2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bE6hTh1Dt2Rf","executionInfo":{"status":"ok","timestamp":1742108027518,"user_tz":-330,"elapsed":59295,"user":{"displayName":"SHRINJITA PAUL (RA2211047010017)","userId":"01697648162985420992"}},"outputId":"4e64d537-c732-4513-e2c9-355fe35a457f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training...\n","Rounds 0\n","Rounds 1000\n","Rounds 2000\n","Rounds 3000\n","Rounds 4000\n","Rounds 5000\n","Rounds 6000\n","Rounds 7000\n","Rounds 8000\n","Rounds 9000\n","Rounds 10000\n","Rounds 11000\n","Rounds 12000\n","Rounds 13000\n","Rounds 14000\n","Rounds 15000\n","Rounds 16000\n","Rounds 17000\n","Rounds 18000\n","Rounds 19000\n","Rounds 20000\n","Rounds 21000\n","Rounds 22000\n","Rounds 23000\n","Rounds 24000\n","Rounds 25000\n","Rounds 26000\n","Rounds 27000\n","Rounds 28000\n","Rounds 29000\n","Rounds 30000\n","Rounds 31000\n","Rounds 32000\n","Rounds 33000\n","Rounds 34000\n","Rounds 35000\n","Rounds 36000\n","Rounds 37000\n","Rounds 38000\n","Rounds 39000\n","Rounds 40000\n","Rounds 41000\n","Rounds 42000\n","Rounds 43000\n","Rounds 44000\n","Rounds 45000\n","Rounds 46000\n","Rounds 47000\n","Rounds 48000\n","Rounds 49000\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pickle\n","\n","# Define board dimensions\n","BOARD_ROWS = 3\n","BOARD_COLS = 3\n","\n","class State:\n","    def __init__(self, p1, p2):\n","        # Initialize the board state with zeros\n","        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n","        self.p1 = p1  # Player 1\n","        self.p2 = p2  # Player 2\n","        self.isEnd = False  # Flag to check if the game has ended\n","        self.boardHash = None  # Stores the board state hash\n","        self.playerSymbol = 1  # Player 1 starts first\n","\n","    def getHash(self):\n","        # Converts board state to a hashable string\n","        self.boardHash = str(self.board.reshape(BOARD_ROWS * BOARD_COLS))\n","        return self.boardHash\n","\n","    def availablePositions(self):\n","        # Returns a list of empty positions on the board\n","        return [(i, j) for i in range(BOARD_ROWS) for j in range(BOARD_COLS) if self.board[i, j] == 0]\n","\n","    def updateState(self, position):\n","        # Updates the board with the current player's move\n","        self.board[position] = self.playerSymbol\n","        # Switch player after making a move\n","        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n","\n","    def winner(self):\n","        # Check for winning conditions\n","        for i in range(BOARD_ROWS):\n","            if sum(self.board[i, :]) == 3:  # Player 1 wins\n","                return 1\n","            if sum(self.board[i, :]) == -3:  # Player 2 wins\n","                return -1\n","\n","        for i in range(BOARD_COLS):\n","            if sum(self.board[:, i]) == 3:  # Column-wise win for Player 1\n","                return 1\n","            if sum(self.board[:, i]) == -3:  # Column-wise win for Player 2\n","                return -1\n","\n","        # Check diagonals\n","        diag1 = sum([self.board[i, i] for i in range(BOARD_ROWS)])\n","        diag2 = sum([self.board[i, BOARD_ROWS - i - 1] for i in range(BOARD_ROWS)])\n","\n","        if diag1 == 3 or diag2 == 3:\n","            return 1\n","        if diag1 == -3 or diag2 == -3:\n","            return -1\n","\n","        # Check for a draw (no available positions left)\n","        if len(self.availablePositions()) == 0:\n","            return 0\n","\n","        return None  # Game is still ongoing\n","\n","    def giveReward(self):\n","        # Assigns rewards to players based on game outcome\n","        result = self.winner()\n","        if result == 1:\n","            self.p1.feedReward(1)\n","            self.p2.feedReward(0)\n","        elif result == -1:\n","            self.p1.feedReward(0)\n","            self.p2.feedReward(1)\n","        else:\n","            self.p1.feedReward(0.1)  # Reward for a draw\n","            self.p2.feedReward(0.5)\n","\n","    def reset(self):\n","        # Resets the board for a new game\n","        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n","        self.boardHash = None\n","        self.isEnd = False\n","        self.playerSymbol = 1\n","\n","    def play(self, rounds=100):\n","        # Simulates training for a given number of rounds\n","        for i in range(rounds):\n","            if i % 1000 == 0:\n","                print(\"Rounds {}\".format(i))\n","            while self.winner() is None:\n","                positions = self.availablePositions()\n","                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n","                self.updateState(p1_action)\n","                self.p1.addState(self.getHash())\n","\n","                if self.winner() is not None:\n","                    self.giveReward()\n","                    self.p1.reset()\n","                    self.p2.reset()\n","                    self.reset()\n","                    break\n","\n","                positions = self.availablePositions()\n","                p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n","                self.updateState(p2_action)\n","                self.p2.addState(self.getHash())\n","\n","                if self.winner() is not None:\n","                    self.giveReward()\n","                    self.p1.reset()\n","                    self.p2.reset()\n","                    self.reset()\n","                    break\n","\n","    def showBoard(self):\n","        # Prints the current board state\n","        for i in range(BOARD_ROWS):\n","            print('-------------')\n","            out = '| '\n","            for j in range(BOARD_COLS):\n","                token = 'x' if self.board[i, j] == 1 else 'o' if self.board[i, j] == -1 else ' '\n","                out += token + ' | '\n","            print(out)\n","        print('-------------')\n","\n","class Player:\n","    def __init__(self, name, exp_rate=0.3):\n","        self.name = name\n","        self.states = []  # Stores states encountered\n","        self.lr = 0.2  # Learning rate\n","        self.exp_rate = exp_rate  # Exploration rate\n","        self.decay_gamma = 0.9  # Discount factor\n","        self.states_value = {}  # Stores value function\n","\n","    def getHash(self, board):\n","        return str(board.reshape(BOARD_COLS * BOARD_ROWS))\n","\n","    def addState(self, state):\n","        self.states.append(state)\n","\n","    def feedReward(self, reward):\n","        # Backpropagates rewards through previous states\n","        for st in reversed(self.states):\n","            if self.states_value.get(st) is None:\n","                self.states_value[st] = 0\n","            self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n","            reward = self.states_value[st]\n","\n","    def reset(self):\n","        self.states = []\n","\n","    def savePolicy(self):\n","        with open('policy_' + str(self.name), 'wb') as fw:\n","            pickle.dump(self.states_value, fw)\n","\n","    def loadPolicy(self, file):\n","        with open(file, 'rb') as fr:\n","            self.states_value = pickle.load(fr)\n","\n","    def chooseAction(self, positions, board, symbol):\n","        return positions[0]  # Currently chooses first available position\n","\n","class HumanPlayer:\n","    def __init__(self, name):\n","        self.name = name\n","\n","    def chooseAction(self, positions, board=None, symbol=None):\n","        while True:\n","            row = int(input(\"Input your action row:\"))\n","            col = int(input(\"Input your action col:\"))\n","            action = (row, col)\n","            if action in positions:\n","                return action\n","\n","# Training phase\n","p1 = Player(\"p1\")\n","p2 = Player(\"p2\")\n","st = State(p1, p2)\n","print(\"training...\")\n","st.play(50000)\n","p1.savePolicy()\n","p2.savePolicy()\n","\n","# Load trained policy and start human vs AI game\n","p1 = Player(\"computer\", exp_rate=0)\n","p1.loadPolicy(\"policy_p1\")\n","p2 = HumanPlayer(\"human\")\n","st = State(p1, p2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vwpFmq9yuNcU","executionInfo":{"status":"ok","timestamp":1742108218982,"user_tz":-330,"elapsed":60885,"user":{"displayName":"SHRINJITA PAUL (RA2211047010017)","userId":"01697648162985420992"}},"outputId":"fade961a-bf7a-4ab9-832f-58823d106bc5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training...\n","Rounds 0\n","Rounds 1000\n","Rounds 2000\n","Rounds 3000\n","Rounds 4000\n","Rounds 5000\n","Rounds 6000\n","Rounds 7000\n","Rounds 8000\n","Rounds 9000\n","Rounds 10000\n","Rounds 11000\n","Rounds 12000\n","Rounds 13000\n","Rounds 14000\n","Rounds 15000\n","Rounds 16000\n","Rounds 17000\n","Rounds 18000\n","Rounds 19000\n","Rounds 20000\n","Rounds 21000\n","Rounds 22000\n","Rounds 23000\n","Rounds 24000\n","Rounds 25000\n","Rounds 26000\n","Rounds 27000\n","Rounds 28000\n","Rounds 29000\n","Rounds 30000\n","Rounds 31000\n","Rounds 32000\n","Rounds 33000\n","Rounds 34000\n","Rounds 35000\n","Rounds 36000\n","Rounds 37000\n","Rounds 38000\n","Rounds 39000\n","Rounds 40000\n","Rounds 41000\n","Rounds 42000\n","Rounds 43000\n","Rounds 44000\n","Rounds 45000\n","Rounds 46000\n","Rounds 47000\n","Rounds 48000\n","Rounds 49000\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"azDieRNdvOcB"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1dOZ5IQ6zBxr-dQuKHGr4Ie-kX5cyQd-w","timestamp":1740711229027}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":0}